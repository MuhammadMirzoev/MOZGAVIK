{
  "title": "Основы машинного обучения",
  "size": "1.8 MB",
  "meta": "ИИ • пример",
  "chapters": [
    {
      "title": "Глава 1. Парадигмы",
      "text": "Контролируемое, неконтролируемое и обучение с подкреплением — три базовые парадигмы ML. Контролируемое использует размеченные данные; неконтролируемое ищет скрытую структуру; RL оптимизирует политику награды.",
      "sections": []
    },
    {
      "title": "Глава 2. Представление и модели",
      "text": "Линейные модели, деревья решений, ансамбли, нейросети. Баланс смещения и дисперсии. Регуляризация (L2, dropout) и нормализация улучшают обобщающую способность.",
      "sections": []
    },
    {
      "title": "Глава 3. Оценка и валидация",
      "text": "Разделение на train/valid/test, кросс-валидация, метрики (Accuracy, Precision/Recall, ROC-AUC, F1). Лик утечки, подбор гиперпараметров, мониторинг в проде.",
      "sections": []
    }
  ],
  "conspect": [
    "Три парадигмы ML и их задачи",
    "Выбор модели = компромисс bias/variance",
    "Оценка качества: валидные метрики и честная валидация",
    "Прод-мониторинг предотвращает деградацию"
  ],
  "qa": [],
  "pages": [
    "Контролируемое, неконтролируемое и обучение с подкреплением — три базовые парадигмы ML. Контролируемое использует размеченные данные; неконтролируемое ищет скрытую структуру; RL оптимизирует политику награды.\n\nЛинейные модели, деревья решений, ансамбли, нейросети. Баланс смещения и дисперсии. Регуляризация (L2, dropout) и нормализация улучшают обобщающую способность.\n\nРазделение на train/valid/test, кросс-валидация, метрики (Accuracy, Precision/Recall, ROC-AUC, F1). Лик утечки, подбор гиперпараметров, мониторинг в проде."
  ]
}