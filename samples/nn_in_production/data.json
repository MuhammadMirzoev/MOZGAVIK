{
  "title": "Нейросети в продакшене",
  "size": "3.1 MB",
  "meta": "ИИ • расширенный пример",
  "chapters": [
    {
      "title": "Глава 1. Данные и конвейеры",
      "text": "Надёжный продакшен начинается с данных. Важны схемы, версионирование, профилирование и тесты на валидность. Конвейеры строятся вокруг инкрементальных обновлений, а сырьё — вокруг контрактов. Формализованные наборы и дата-каталоги уменьшают сюрпризы и делают обучение воспроизводимым.",
      "sections": []
    },
    {
      "title": "Глава 2. Архитектуры и представления",
      "text": "Выбор между CNN, RNN, трансформерами и смешанными подходами диктуется задачей и бюджетом. Важнее не модель, а способ кодировать предметную область: признаки, токенизация, эмбеддинги. Хорошая архитектура позволяет эволюционировать без полной перестройки пайплайна.",
      "sections": []
    },
    {
      "title": "Глава 3. Обучение и контроль качества",
      "text": "Честная валидация исключает утечки. Автоматические отчёты сравнивают метрики по релизам; регрессии ловят до выката. Обучение мониторится по кривым потерь и распределениям признаков, а гиперпараметры логируются вместе с окружением.",
      "sections": []
    },
    {
      "title": "Глава 4. Деплоймент и инфраструктура",
      "text": "Онлайн-инференс, батч-процессы и стриминг требуют разных SLA. Контейнеризация, тритон/onnx/torchserve, авто-скейл, кэширование эмбеддингов. Каталоги моделей и серые выкаты позволяют управлять рисками.",
      "sections": []
    },
    {
      "title": "Глава 5. Наблюдаемость и деградации",
      "text": "Дрифт данных и дрифт концепции выявляются за счёт распределений, PSI/JS-дивергенций и канареечных наборов. Алерты триггерятся по метрикам качества и латентности. Важно уметь быстро откатываться и воспроизводить прошлый запуск.",
      "sections": []
    },
    {
      "title": "Глава 6. Переобучение на лету",
      "text": "Контур обратной связи — сбор фидбэка, слабая разметка, активное обучение. Повторная тренировка по расписанию, warm-start и защита от регрессий. Оркестрация: Airflow/Argo + фичестор + хранилище артефактов.",
      "sections": []
    }
  ],
  "conspect": [
    "Данные и контракты — фундамент надёжности",
    "Архитектура под задачу и бюджет, эволюционность",
    "Мониторинг качества и дрифта, быстрый откат",
    "Автоматизация переобучения и оркестрация"
  ],
  "qa": [],
  "pages": [
    "Надёжный продакшен начинается с данных. Важны схемы, версионирование, профилирование и тесты на валидность. Конвейеры строятся вокруг инкрементальных обновлений, а сырьё — вокруг контрактов. Формализованные наборы и дата-каталоги уменьшают сюрпризы и делают обучение воспроизводимым.\n\nВыбор между CNN, RNN, трансформерами и смешанными подходами диктуется задачей и бюджетом. Важнее не модель, а способ кодировать предметную область: признаки, токенизация, эмбеддинги. Хорошая архитектура позволяет эволюционировать без полной перестройки пайплайна.\n\nЧестная валидация исключает утечки. Автоматические отчёты сравнивают метрики по релизам; регрессии ловят до выката. Обучение мониторится по кривым потерь и распределениям признаков, а гиперпараметры логируются вместе с окружением.\n\nОнлайн-инференс, батч-процессы и стриминг требуют разных SLA. Контейнеризация, тритон/onnx/torchserve, авто-скейл, кэширование эмбеддингов. Каталоги моделей и серые выкаты позволяют управлять рисками.",
    "Дрифт данных и дрифт концепции выявляются за счёт распределений, PSI/JS-дивергенций и канареечных наборов. Алерты триггерятся по метрикам качества и латентности. Важно уметь быстро откатываться и воспроизводить прошлый запуск.\n\nКонтур обратной связи — сбор фидбэка, слабая разметка, активное обучение. Повторная тренировка по расписанию, warm-start и защита от регрессий. Оркестрация: Airflow/Argo + фичестор + хранилище артефактов."
  ]
}