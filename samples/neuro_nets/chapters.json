{
  "chapters": [
    {
      "title": "Нейрон как функция",
      "text": "Искусственный нейрон вычисляет взвешенную сумму входов, затем применяет нелинейность. Популярные функции: ReLU, sigmoid, tanh. Нелинейности позволяют моделировать сложные зависимости.",
      "sections": []
    },
    {
      "title": "Обучение",
      "text": "Градиентный спуск и обратное распространение ошибки. Регуляризация (L2, dropout) помогает избежать переобучения.",
      "sections": [
        {
          "title": "Градиентный спуск",
          "text": "Изменяем веса в направлении антиградиента функции потерь.",
          "sections": []
        }
      ]
    }
  ]
}